# 图像分割(含语义/实例/全景分割)

这是我早些时候整理的计算机视觉和图像分割资料，还算比较全面：[计算机视觉笔记及资料整理（含图像分割、目标检测）.md](./计算机视觉笔记及资料整理（含图像分割、目标检测）.md)



---

我在幕布上的记录：[04-图像语义分割(含FCN、UNet、SegNet、PSPNet、Deeplabv1&v2&v3等)](https://mubu.com/doc/1OEfnuDXAc)

- 常规的深度卷积神经网络 (如 AlexNet 和 VGG ) 并不适用于密集预测的任务。首先，这些模型包含许多用于减小输入特征的空间维度的层。结果，这些层最终产生缺乏清晰细节的高度抽象的特征矢量。第二，全连接层在计算过程中具有固定的输入规模和松散的空间信息。

- 作为一个例子，试想通过一系列的卷积来传递图像，而不是使用池化和全连接层。我们将每次卷积都设置成步长为 1，padding 为「SAME」。通过这种处理，每一次卷积都保留了输入的空间维度。我们可以堆叠很多这种卷积，并最终得到一个分割模型。用于密集预测的全卷积神经网络。**请注意，不存在池化层和全连接层。**

- 这个模型可以输出形状为 [W,H,C] 的概率张量，其中 W 和 H 代表的是宽度和高度，C 代表的是类别标签的个数。在第三个维度上应用最大化函数会得到形状为 [W,H,1] 的张量。然后，我们计算真实图像和我们的预测的每个像素之间的交叉熵。最终，我们对计算结果取平均值，并且使用反向传播算法训练网络。

- **然而**，这个方法存在一个问题。正如前面所提到的，使用步长为 1，padding 为「SAME」，保留了输入的维度。但是，那样做的后果就是模型会极其耗费内存，而且计算复杂度也是很大的。

- 为了缓解这个问题，分割网络通常会有三个主要的组成部分：卷积层、降采样层和上采样层。

  - **①图像语义分割模型的编码器-解码器结构。**
    - 在卷积神经网络中实现降采样的常用方式有两个：通过改变卷积步长或者常规的池化操作。一般而言，降采样的目标就是减少给定特征图的空间维度。因此，降采样可以让我们在执行更深的卷积运算时不用过多地考虑内存。然而，这样一来在计算的时候会损失一些特征。
    - 值得注意的是，这个架构的第一部分看上去类似于普通的分类深度卷积神经网络。不同的是，其中没有设置全连接层。
    - 有很多基于编码器—解码器结构的神经网络实现。**FCNs、SegNet，以及 UNet 是最流行的几个。**
  - **②膨胀卷积，抛弃了池化层。**

  ——*Form [语义分割网络DeepLab-v3的架构设计思想和TensorFlow实现 | 机器之心](https://www.jiqizhixin.com/articles/deeplab-v3)*

  













---

## 语义分割梳理

在学习完常见的语义分割模型后，可以看下面这些文章再梳理下。

### 语义分割发展和历史

（1）[10分钟看懂全卷积神经网络（FCN）：语义分割深度模型先驱 - TinyMind](https://www.tinymind.cn/articles/3815)

所有的发展都是漫长的技术积累，加上一些外界条件满足时就会产生质变。我们简单总结了图像分割的几个时期：

**2000年之前，数字图像处理时我们采用方法基于几类：阈值分割、区域分割、边缘分割、纹理特征、聚类等。**

**2000年到2010年期间， 主要方法有四类：基于图论、聚类、分类以及聚类和分类结合。**

**2010年至今，神经网络模型的崛起和深度学习的发展，主要涉及到几种模型：**

![](https://file.ai100.com.cn/files/sogou-articles/original/fb9f37e6-e925-4142-904b-3707fb984cd4/fb9f37e6-e925-4142-904b-3707fb984cd4)

截至到2017年底，我们已经分化出了数以百计的模型结构。当然，经过从技术和原理上考究，我们发现了一个特点，那就是当前最成功的图像分割深度学习技术都是基于一个共同的先驱：FCN（Fully Convolutional Network，全卷积神经网络）。

发展历程：

- 2014年 FCN 模型，主要贡献为在语义分割问题中推广使用端对端卷积神经网络，使用反卷积进行上采样

- 2015年 U-net 模型，构建了一套完整 的编码解码器

- 2015年 SegNet 模型，将最大池化转换为解码器来提高分辨率

- 2015年 Dilated Convolutions（空洞卷积），更广范围内提高了内容的聚合并不降低分辨率

- 2016年 DeepLab v1&v2

- 2016年 RefineNet 使用残差连接，降低了内存使用量，提高了模块间的特征融合

- 2016年 PSPNet 模型

- 2017年 Large Kernel Matters

- 2017年 DeepLab V3

以上几种模型可以按照语义分割模型的独有方法进行分类，如专门池化（PSPNet、DeepLab），编码器-解码器架构（SegNet、E-Net），多尺度处理（DeepLab）、条件随机场（CRFRNN）、空洞卷积（DiatedNet、DeepLab）和跳跃连接（FCN）。



（2）[深度学习（十九）——FCN, SegNet, DeconvNet, DeepLab, ENet, GCN](https://blog.csdn.net/antkillerfarm/article/details/79524417)

**前DL时代的语义分割：** 

Grab cut是微软剑桥研究院于2004年提出的著名交互式图像语义分割方法。与N-cut一样，grab cut同样也是基于图划分，不过grab cut是其改进版本，可以看作迭代式的语义分割算法。Grab cut利用了图像中的纹理（颜色）信息和边界（反差）信息，只要少量的用户交互操作即可得到比较好的前后背景分割结果。

在Grab cut中，RGB图像的前景和背景分别用一个高斯混合模型（Gaussian mixture model, GMM）来建模。两个GMM分别用以刻画某像素属于前景或背景的概率，每个GMM高斯部件（Gaussian component）个数一般设为k=5。接下来，利用吉布斯能量方程（Gibbs energy function）对整张图像进行全局刻画，而后迭代求取使得能量方程达到最优值的参数作为两个GMM的最优参数。GMM确定后，某像素属于前景或背景的概率就随之确定下来。

在与用户交互的过程中，Grab cut提供两种交互方式：一种以包围框（Bounding box）为辅助信息；另一种以涂写的线条（Scribbled line）作为辅助信息。以下图为例，用户在开始时提供一个包围框，grab cut默认的认为框中像素中包含主要物体／前景，此后经过迭代图划分求解，即可返回扣出的前景结果，可以发现即使是对于背景稍微复杂一些的图像，grab cut仍有不俗表现。

不过，在处理下图时，grab cut的分割效果则不能令人满意。此时，需要额外人为的提供更强的辅助信息：用红色线条／点标明背景区域，同时用白色线条标明前景区域。在此基础上，再次运行grab cut算法求取最优解即可得到较为满意的语义分割结果。Grab cut虽效果优良，但缺点也非常明显，一是仅能处理二类语义分割问题，二是需要人为干预而不能做到完全自动化。

不难看出，前DL时代的语义分割工作多是根据图像像素自身的低阶视觉信息（Low-level visual cues）来进行图像分割。由于这样的方法没有算法训练阶段，因此往往计算复杂度不高，但是在较困难的分割任务上（如果不提供人为的辅助信息），其分割效果并不能令人满意。



（3）[基于深度学习的语义分割简述及初探[译] - AIUAI](https://www.aiuai.cn/aifarm599.html)

语义分割是对图像的一种更精细的推断与理解，由粗到细为：

- 图像分类 - 初级的图片理解，其对整张图片进行整体理解.
- 目标定位与检测 - 不仅提供图像内的类别，还包括相对于物体类别的空间为位置信息.
- 语义分割 - 对每个图像像素进行密集预测，得到像素类别信息.

。。。

[1] 基于区域的语义分割

[2] 基于 FCN 的语义分割

[3] 弱监督语义分割



### 语义分割模型发展

（1）[语义分割中的深度学习方法全解：从FCN、SegNet到各代DeepLab - 知乎](https://zhuanlan.zhihu.com/p/27794982)

该文要点：

1. FCN网络；
2. SegNet网络；
3. 空洞卷积(Dilated Convolutions)；
4. DeepLab (v1和v2)；
5. RefineNet；
6. PSPNet；
7. 大内核(Large Kernel Matters)；
8. DeepLab v3；

对于上面的每篇论文，将会分别指出主要贡献并进行解释，也贴出了这些结构在 VOC2012 数据集中的测试分值IOU。

（2）[主要语义分割网络模型概览[转] - AIUAI](https://www.aiuai.cn/aifarm602.html)

图像的语义分割是将输入图像中的每个像素分配一个语义类别，以得到像素化的密集分类。

虽然自 2007 年以来，语义分割/场景解析一直是计算机视觉社区的一部分，但与计算机视觉中的其他领域很相似，自 2014 年 Long 等人首次使用全卷积神经网络对自然图像进行端到端分割，语义分割才有了重大突破。

本文作者总结了 FCN、SegNet、U-Net、FC-Densenet E-Net 和 Link-Net、RefineNet、PSPNet、Mask-RCNN 以及一些半监督方法，如 DecoupledNet 和 GAN-SS，并为其中的一些网络提供了 PyTorch 实现. 在文章的最后一部分，作者总结了一些流行的数据集，并展示了一些网络训练的结果。





